from typing import List, Tuple, Dict
import torch
from torch import Tensor, nn
from torchtext.vocab import Vocab
import tokenizers as tk
import torch.nn.functional as F


from utils import pred_token_within_range, subsequent_mask
from vocab import (
    HTML_TOKENS,
    TASK_TOKENS,
    RESERVED_TOKENS,
    BBOX_TOKENS,
)


VALID_HTML_TOKEN = ["<eos>"] + HTML_TOKENS
INVALID_CELL_TOKEN = (
    ["<sos>", "<pad>", "<empty>", "<sep>"] + TASK_TOKENS + RESERVED_TOKENS
)
VALID_BBOX_TOKEN = [
    "<eos>"
] + BBOX_TOKENS  # image size will be addressed after instantiation

# MIX_HTML_TOKENSì™€ VALID_MIX_TOKENS ìƒì„±
# VALID_HTML_TOKEN : 49
# INVALID_CELL_TOKEN : 18
# VALID_BBOX_TOKEN : 881




class Batch_MIX:
    """Wrap up a batch of training samples with different training targets.
    The input is not torch tensor
    Shape of the image (src): B, S, E
    Shape of the text (tgt): B, N, S, E (M includes 1 table detection, 1 structure, 1 cell, and multiple bbox)
    Reshape text to (B * N, S, E) and inflate the image to match the shape of the text

    Args:
    ----
        device: gpu id
    """

    def __init__(
        self,
        device: torch.device,
        target: str,
        vocab_html: Vocab, # âœ…
        vocab_bbox: Vocab, # âœ…
        obj: List,# âœ…
        ) -> None:
        
        self.device = device
        self.image = obj[0].to(device)
        self.name = obj[1]["filename"]
        self.target = target
        self.vocab_html = vocab_html # âœ…
        self.vocab_bbox = vocab_bbox # âœ…
        self.image_size = self.image.shape[-1]

        if "table" in target:
            raise NotImplementedError

        # âœ…
        self.valid_html_token = [vocab_html.token_to_id(i) for i in VALID_HTML_TOKEN]

        (
            self.html_src,
            self.html_tgt,
            self.html_casual_mask,
            self.html_padding_mask,
        ) = self._prepare_transformer_input(obj[1]["html"]) # âœ…

        # âœ…
        (
            self.bbox_src,
            self.bbox_tgt,
            self.bbox_casual_mask,
            self.bbox_padding_mask,
        ) = self._prepare_transformer_input(obj[1]["bbox"]) # âœ…

        vocab_html = self.vocab_html.get_vocab()
        vocab_bbox = self.vocab_bbox.get_vocab()
        self.bbox_target_indices = [idx for token, idx in vocab_bbox.items() if "bbox" in token]
        self.html_target_indices = [
        vocab_html.get(">[]</td>", None),
        vocab_html.get("<td>[]</td>", None)
        ]

        self.old_to_new_mapping_html, self.old_to_new_mapping_bbox, self.html_target_indices, self.bbox_target_indices\
            = create_mix_tokens(vocab_html, vocab_bbox)

        self.get_mix_vocab_size()

        self.embedding_dim_html = None
        self.embedding_dim_bbox = None
        

    def _prepare_transformer_input(
        self, seq: List[tk.Encoding]) -> Tuple[Tensor, Tensor, Tensor, Tensor]:
        tmp = [i.ids for i in seq]
        tmp = torch.tensor(tmp, dtype=torch.int32)
        src = tmp[:, :-1].to(self.device)
        tgt = tmp[:, 1:].type(torch.LongTensor).to(self.device)
        casual_mask = subsequent_mask(src.shape[-1]).to(self.device)
        tmp = [i.attention_mask[:-1] for i in seq]  # padding mask
        tmp = torch.tensor(tmp, dtype=torch.bool)
        padding_mask = (~tmp).to(self.device)

        return src, tgt, casual_mask, padding_mask


    def _inference_one_task(
        self, model, memory, src, casual_mask, padding_mask, use_ddp
    ):
        if use_ddp:
            out = model.module.decode(memory, src, casual_mask, padding_mask)
            out = model.module.generator(out)
        else:
            out = model.decode(memory, src, casual_mask, padding_mask)
            out = model.generator(out)

        return out


    def inference(
        self,
        model_html: nn.Module, # âœ…
        model_bbox: nn.Module, # âœ…
        criterion_html: nn.Module,
        criterion_bbox: nn.Module,
        criterion_mix: nn.Module,
        loss_weights: dict = None,
        use_ddp: bool = True,
    ) -> Tuple[Dict, Dict]:
        pred = dict()
        loss = dict(table=0, html=0, cell=0, bbox=0)

        self.set_embedding_dim(model_html, model_bbox)
        
        if use_ddp:
            memory_html = model_html.module.encode(self.image) # âœ…
            memory_bbox = model_bbox.module.encode(self.image) # âœ…
        else:
            memory_html = model_html.encode(self.image)
            memory_bbox = model_bbox.encode(self.image)

        # inference + suppress invalid logits + compute loss
        out_html = self._inference_one_task(
                model_html,
                memory_html,
                self.html_src,
                self.html_casual_mask,
                self.html_padding_mask,
                use_ddp,
            )

        pred_html_logits = pred_token_within_range(
            out_html, white_list=self.valid_html_token).permute(0, 2, 1)
        pred["html"] = pred_html_logits
        loss["html"] = criterion_html(pred_html_logits, self.html_tgt)


        out_bbox = self._inference_one_task(
            model_bbox,
            memory_bbox,
            self.bbox_src,
            self.bbox_casual_mask,
            self.bbox_padding_mask,
            use_ddp,
        )        
        
        
        pred_bbox_logits = out_bbox.permute(0, 2, 1)
        pred["bbox"] = pred_bbox_logits
        loss["bbox"] = criterion_bbox(pred_bbox_logits, self.bbox_tgt)


        # Softmax í™•ë¥  ë¶„í¬ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        probs_html = F.softmax(out_html, dim=-1)    # (B, S_html, V_html)
        probs_bbox = F.softmax(out_bbox, dim=-1)      # (B, S_bbox, V_bbox)

        # <eos> ì´í›„ë¥¼ pad í† í° í™•ë¥ ë¡œ ë§ˆìŠ¤í‚¹í•˜ëŠ” ì²˜ë¦¬ëŠ” í•„ìš” ì‹œ ì¶”ê°€ (ì—¬ê¸°ì„œëŠ” ìƒëµ)

        # Differentiable combine: soft predictions ê²°í•©
        combined_soft_pred = self.combine_soft(probs_html, probs_bbox)  
        # combined_soft_predì˜ shape: (B, L, X), ì—¬ê¸°ì„œ X == V_html (ì˜ˆ: 1397)

        # --- ì¶”ê°€: combined_soft_predì˜ ë§ˆì§€ë§‰ ì°¨ì›ì„ ëª¨ë¸ ì„ë² ë”© ì°¨ì›ìœ¼ë¡œ ë§ì¶¤ ---
        # (ë§Œì•½ self.vocab_html.get_vocab_size() != self.embedding_dim_html)
        if combined_soft_pred.size(-1) != self.embedding_dim_html:
            # ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ë‹¤ë©´ projection layer ìƒì„±
            if not hasattr(self, "proj_to_mix"):
                # self.vocab_html.get_vocab_size()ê°€ ë³´í†µ soft_htmlì˜ ë§ˆì§€ë§‰ ì°¨ì› (ì˜ˆ: 1397)ì…ë‹ˆë‹¤.
                self.proj_to_mix = nn.Linear(combined_soft_pred.size(-1), self.embedding_dim_html).to(self.device)
            combined_soft_pred = self.proj_to_mix(combined_soft_pred)
        # -----------------------------------------------------------------------

        # GT ê²°í•©: ê¸°ì¡´ combine í•¨ìˆ˜ë¡œ discrete token id ì‹œí€€ìŠ¤ ìƒì„±
        combined_tokens_tgt = self.combine(self.html_tgt, self.bbox_tgt)  # (B, L_t)
        # GT ê²°í•© í† í°ë“¤ì„ ëª¨ë¸ì˜ ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ë³€í™˜ (ì—¬ê¸°ì„œëŠ” html ì„ë² ë”© ì‚¬ìš©)
        combined_tokens_tgt_embed = self.embedding_html(combined_tokens_tgt)  # (B, L_t, d_model)

        # ë‘ ê²°í•© í‘œí˜„ì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ pad_to_same_lengthë¡œ ë§ì¶¤
        combined_tokens_tgt_embed, combined_soft_pred = self.pad_to_same_length(
            combined_tokens_tgt_embed, combined_soft_pred, pad_value=0.0
        )

        # mix loss ê³„ì‚°: mix_classifierë¡œ continuous í‘œí˜„ì„ merged vocabulary logitsë¡œ ë³€í™˜
        if not hasattr(self, "mix_classifier"):
            self.mix_vocab_size = self.get_mix_vocab_size()
            self.mix_classifier = nn.Linear(self.embedding_dim_html, self.mix_vocab_size).to(self.device)
        mix_logits = self.mix_classifier(combined_soft_pred)  # (B, L, mix_vocab_size)
        mix_logits = mix_logits.permute(0, 2, 1)  # (B, mix_vocab_size, L)

        # criterion_mixëŠ” nn.CrossEntropyLoss, target: (B, L) (ì •ìˆ˜ token id)
        new_loss_2_combine = criterion_mix(mix_logits, combined_tokens_tgt.long())
        loss['mix'] = new_loss_2_combine

        total = torch.tensor(0.0).to(probs_bbox.device)
        for k, v in loss_weights.items():
            total += loss[k] * v
        loss["total"] = total

        return loss, pred

    def get_mix_vocab_size(self) -> int:
        """
        Computes the merged vocabulary size based on the old_to_new_mapping for html and bbox.
        """
        max_val = 0
        for mapping in self.old_to_new_mapping_html.values():
            if isinstance(mapping, dict):
                max_val = max(max_val, mapping["left"], mapping["right"])
            else:
                max_val = max(max_val, mapping)
        for mapping in self.old_to_new_mapping_bbox.values():
            max_val = max(max_val, mapping)
        return max_val + 1


    def set_embedding_dim(self, model_html: nn.Module, model_bbox: nn.Module):
        """
        Sets the embedding dimensions based on the provided models.
        Since EncoderDecoder does not have a config attribute,
        we extract the hidden dimension (d_model) from the token_embed.
        ê·¸ë¦¬ê³  ìƒì„±ëœ ì„ë² ë”© ë ˆì´ì–´ë¥¼ self.deviceë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.
        """
        # DDP ë˜í•‘ ì—¬ë¶€ í™•ì¸
        if hasattr(model_html, "module"):
            model_html = model_html.module
        if hasattr(model_bbox, "module"):
            model_bbox = model_bbox.module

        # model_html.token_embed.embedding.weight.shape: (vocab_size, d_model)
        self.embedding_dim_html = model_html.token_embed.embedding.weight.shape[1]
        self.embedding_dim_bbox = model_bbox.token_embed.embedding.weight.shape[1]

        # ì„ë² ë”© ë ˆì´ì–´ ìƒì„± í›„, self.deviceë¡œ ì´ë™
        self.embedding_html = nn.Embedding(self.vocab_html.get_vocab_size(), self.embedding_dim_html).to(self.device)
        self.embedding_bbox = nn.Embedding(self.vocab_bbox.get_vocab_size(), self.embedding_dim_bbox).to(self.device)



    def combine_soft(self, soft_html: torch.Tensor, soft_bbox: torch.Tensor) -> torch.Tensor:
        """
        soft_html: (B, S_html, V_html) â€” html decoderì˜ softmax ê²°ê³¼
        soft_bbox: (B, S_bbox, V_bbox) â€” bbox decoderì˜ softmax ê²°ê³¼

        ê° í™•ë¥  ë¶„í¬ë¥¼ ì„ë² ë”© ê³µê°„ì˜ ê¸°ëŒ€ê°’(soft embedding)ìœ¼ë¡œ ë³€í™˜í•œ í›„,
        html target í† í°(ì˜ˆ: self.html_target_indices)ì— í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ì— ëŒ€í•´ bbox ì„ë² ë”©ì„ ê°€ì¤‘í•©í•©ë‹ˆë‹¤.
        
        ë§Œì•½ ë‘ í…ì„œì˜ ì‹œí€€ìŠ¤ ê¸¸ì´(S_html, S_bbox)ê°€ ë‹¤ë¥´ë©´, ì§§ì€ ìª½ì„ ì˜¤ë¥¸ìª½ì— 0ìœ¼ë¡œ íŒ¨ë”©í•˜ì—¬ ê¸¸ì´ë¥¼ ë§ì¶¥ë‹ˆë‹¤.
        """
        B = soft_html.shape[0]
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ ë§ì¶”ê¸°: (B, S, V)
        if soft_html.shape[1] < soft_bbox.shape[1]:
            pad_size = soft_bbox.shape[1] - soft_html.shape[1]
            # pad (last dimension: no pad; second-last dimension: pad at end)
            soft_html = torch.nn.functional.pad(soft_html, (0, 0, 0, pad_size), value=0.0)
        elif soft_bbox.shape[1] < soft_html.shape[1]:
            pad_size = soft_html.shape[1] - soft_bbox.shape[1]
            soft_bbox = torch.nn.functional.pad(soft_bbox, (0, 0, 0, pad_size), value=0.0)
        
        # ê¸°ëŒ€ ì„ë² ë”© ê³„ì‚°
        # self.embedding_html.weight: (V_html, d_html)
        # self.embedding_bbox.weight: (V_bbox, d_bbox)
        soft_embed_html = torch.matmul(soft_html, self.embedding_html.weight)   # (B, S, d_html)
        soft_embed_bbox = torch.matmul(soft_bbox, self.embedding_bbox.weight)   # (B, S, d_bbox)
        
        # ë§Œì•½ ë‘ ì„ë² ë”©ì˜ ì°¨ì›ì´ ë‹¤ë¥´ë©´ bbox ì„ë² ë”©ì„ html ì„ë² ë”© ì°¨ì›ìœ¼ë¡œ ì„ í˜• ë³€í™˜
        if soft_embed_html.size(-1) != soft_embed_bbox.size(-1):
            if not hasattr(self, 'bbox_to_html_proj'):
                self.bbox_to_html_proj = nn.Linear(soft_embed_bbox.size(-1), soft_embed_html.size(-1)).to(soft_embed_bbox.device)
            soft_embed_bbox = self.bbox_to_html_proj(soft_embed_bbox)  # (B, S, d_html)
        
        # html target í† í°ì— í•´ë‹¹í•˜ëŠ” í™•ë¥  massë¥¼ êµ¬í•¨.
        # target_mask: (V_html,) - html target í† í°ì— í•´ë‹¹í•˜ë©´ 1, ì•„ë‹ˆë©´ 0.
        target_mask = torch.zeros(soft_html.size(-1), device=soft_html.device)
        for idx in self.html_target_indices:
            if idx is not None:
                target_mask[idx] = 1.0
        # ê° ìœ„ì¹˜ì—ì„œ html soft ì˜ˆì¸¡ì—ì„œ target í† í° í™•ë¥ ì˜ í•© â†’ (B, S, 1)
        target_indicator = torch.matmul(soft_html, target_mask.unsqueeze(-1))
        
        # ë‹¨ìˆœ ê²°í•©: html ì„ë² ë”©ì— target_indicatorê°€ í´ìˆ˜ë¡ bbox ì„ë² ë”©ì˜ ì˜í–¥ì„ ë” ë¶€ì—¬
        combined = soft_embed_html + target_indicator * soft_embed_bbox
        # ê²°ê³¼: (B, S, d_html)
        return combined



    def combine(self, token_html, token_bbox):
        ##############################
        # HTML í† í° ì²˜ë¦¬ (ìµœì í™” ì ìš©)
        ##############################
        batch_size, seq_length = self.html_tgt.shape

        # ì‚¬ì „: HTML mapping í…Œì´ë¸”ê³¼ í™•ì¥ ì—¬ë¶€ í”Œë˜ê·¸ë¥¼ GPU í…ì„œë¡œ ë¯¸ë¦¬ ìƒì„±
        if not hasattr(self, '_html_mapping_table'):
            vocab_size_html = max(self.old_to_new_mapping_html.keys()) + 1
            mapping_table = torch.zeros((vocab_size_html, 2), dtype=torch.long, device=token_html.device)
            is_expanded = torch.zeros(vocab_size_html, dtype=torch.bool, device=token_html.device)
            for token_id, mapping in self.old_to_new_mapping_html.items():
                if isinstance(mapping, dict):
                    mapping_table[token_id, 0] = mapping["left"]
                    mapping_table[token_id, 1] = mapping["right"]
                    is_expanded[token_id] = True
                else:
                    mapping_table[token_id, 0] = mapping
                    # ë‘ ë²ˆì§¸ ìŠ¬ë¡¯ì€ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ë‚¨ê¹€
            self._html_mapping_table = mapping_table
            self._html_is_expanded = is_expanded

        mapping_table = self._html_mapping_table
        is_expanded = self._html_is_expanded

        # token_html: (B, S) â†’ left í† í°, í™•ì¥ í”Œë˜ê·¸, right í† í° (ëª¨ë‘ (B, S))
        left_tokens = mapping_table[token_html, 0]     # ê¸°ë³¸ ë³€í™˜ ê°’
        expanded_flags = is_expanded[token_html]         # Trueë©´ 2ê°œ í† í°ìœ¼ë¡œ í™•ì¥
        right_tokens = mapping_table[token_html, 1]      # í™•ì¥ ì‹œ ë‘ ë²ˆì§¸ í† í°

        # ê° ë°°ì¹˜ë³„ë¡œ í™•ì¥ëœ ì‹œí€€ìŠ¤ ìƒì„± (ë°°ì¹˜ í¬ê¸°ê°€ ì‘ë‹¤ê³  ê°€ì •)
        new_token_html_list = []
        for b in range(batch_size):
            tokens_b = []
            # GPU í…ì„œëŠ” .item()ì„ í˜¸ì¶œí•˜ë©´ CPUë¡œ ì˜®ê²¨ì§€ë¯€ë¡œ, ê°€ëŠ¥í•˜ë©´ ì¸ë±ì‹± í›„ í•œ ë²ˆì— ì²˜ë¦¬
            left_b = left_tokens[b]
            right_b = right_tokens[b]
            flags_b = expanded_flags[b]
            for i in range(seq_length):
                if flags_b[i].item():  # í™•ì¥ì´ í•„ìš”í•œ ê²½ìš°
                    tokens_b.append(left_b[i])
                    tokens_b.append(right_b[i])
                else:
                    tokens_b.append(left_b[i])
            # tokens_bëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ 1D í…ì„œ; pad_sequence í›„ ê²°í•© ì˜ˆì •
            new_token_html_list.append(torch.stack(tokens_b))
        # ëª¨ë“  ë°°ì¹˜ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ pad ì²˜ë¦¬ (pad value: 0)
        new_token_html = torch.nn.utils.rnn.pad_sequence(new_token_html_list, batch_first=True, padding_value=0)

        ##############################
        # BBOX í† í° ì²˜ë¦¬ (ì™„ì „ ë²¡í„°í™”)
        ##############################
        # ì‚¬ì „: BBOX mapping í…Œì´ë¸”ì„ GPU í…ì„œë¡œ ìƒì„±
        if not hasattr(self, '_bbox_mapping_table'):
            vocab_size_bbox = max(self.old_to_new_mapping_bbox.keys()) + 1
            mapping_tensor_bbox = torch.zeros(vocab_size_bbox, dtype=torch.long, device=token_bbox.device)
            for token_id, mapping in self.old_to_new_mapping_bbox.items():
                mapping_tensor_bbox[token_id] = mapping
            self._bbox_mapping_table = mapping_tensor_bbox
        mapping_tensor_bbox = self._bbox_mapping_table
        # token_bbox: (B, S) â†’ vectorized mapping
        new_token_bbox = mapping_tensor_bbox[token_bbox]  # shape: (B, seq_length)

        ##############################
        # Combined Tokens ìƒì„±
        ##############################
        # target setì„ GPU í…ì„œë¡œ ë³€í™˜ (ë©¤ë²„ì‹­ í…ŒìŠ¤íŠ¸ì— í™œìš©)
        html_target_tensor = torch.tensor(list(self.html_target_indices), device=new_token_html.device)
        bbox_target_tensor = torch.tensor(list(self.bbox_target_indices), device=new_token_bbox.device)

        combined_tokens_list = []
        for b in range(batch_size):
            # HTML ê²°í•© ëŒ€ìƒ í† í°: GPU ì—°ì‚°ìœ¼ë¡œ membership test (í•˜ì§€ë§Œ, ìµœì¢… ê²°í•©ì€ íŒŒì´ì¬ ë£¨í”„ë¡œ ì§„í–‰)
            html_tokens_b = new_token_html[b]  # shape: (L,)
            bbox_tokens_b = new_token_bbox[b]  # shape: (S,)
            # torch.isinë¥¼ ì‚¬ìš©í•´ bbox í•„í„°ë§ (vectorized)
            mask_bbox = torch.isin(bbox_tokens_b, bbox_target_tensor)
            filtered_bbox = bbox_tokens_b[mask_bbox]
            bbox_ptr = 0
            combined_batch = []
            for token in html_tokens_b:
                combined_batch.append(token)
                # html_target_setì€ íŒŒì´ì¬ setì´ë¯€ë¡œ, membership ì²´í¬ëŠ” .item() í›„ ì§„í–‰
                if token.item() in self.html_target_indices:
                    # ìµœëŒ€ 4ê°œì˜ bbox í† í° ì‚½ì…
                    num_to_insert = 4
                    if bbox_ptr < filtered_bbox.numel():
                        end = min(bbox_ptr + num_to_insert, filtered_bbox.numel())
                        combined_batch.extend(filtered_bbox[bbox_ptr:end])
                        bbox_ptr = end
            # ë¦¬ìŠ¤íŠ¸ë¥¼ í…ì„œë¡œ ë³€í™˜
            combined_tokens_list.append(torch.stack(combined_batch))
        # ë°°ì¹˜ë³„ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ pad ì²˜ë¦¬ (padding_value: 2)
        combined_tokens = torch.nn.utils.rnn.pad_sequence(combined_tokens_list, batch_first=True, padding_value=2)

        return combined_tokens


    def pad_to_same_length(self, t1: Tensor, t2: Tensor, pad_value: int = 0) -> Tuple[Tensor, Tensor]:
        # ë‘ í…ì„œì˜ ë‘ ë²ˆì§¸ ì°¨ì›(ì‹œí€€ìŠ¤ ê¸¸ì´)ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ê³„ì‚°
        max_len = max(t1.shape[1], t2.shape[1])
        if t1.shape[1] < max_len:
            pad_size = max_len - t1.shape[1]
            # (left_pad, right_pad) í˜•ì‹ìœ¼ë¡œ pad; ì—¬ê¸°ì„œëŠ” ì˜¤ë¥¸ìª½ì— íŒ¨ë”©
            t1 = torch.nn.functional.pad(t1, (0, pad_size), value=pad_value)
        if t2.shape[1] < max_len:
            pad_size = max_len - t2.shape[1]
            t2 = torch.nn.functional.pad(t2, (0, pad_size), value=pad_value)
        return t1, t2






def configure_optimizer_weight_decay(
    model: nn.Module, weight_decay: float
) -> List[Dict]:
    weight_decay_blacklist = (nn.LayerNorm, nn.BatchNorm2d, nn.Embedding)

    if hasattr(model, "no_weight_decay"):
        skip_list = model.no_weight_decay()
    decay = set()
    no_decay = set()
    for mn, m in model.named_modules():
        for pn, p in m.named_parameters():
            fpn = "%s.%s" % (mn, pn) if mn else pn  # full param name
            if pn.endswith("bias"):
                no_decay.add(fpn)
            elif pn.endswith("weight") and isinstance(m, weight_decay_blacklist):
                no_decay.add(fpn)
            elif pn in skip_list:
                no_decay.add(fpn)

    param_dict = {pn: p for pn, p in model.named_parameters()}
    decay = param_dict.keys() - no_decay

    optim_groups = [
        {
            "params": [param_dict[pn] for pn in sorted(list(decay))],
            "weight_decay": weight_decay,
        },
        {
            "params": [param_dict[pn] for pn in sorted(list(no_decay))],
            "weight_decay": 0.0,
        },
    ]

    return optim_groups



def turn_off_beit_grad(model: nn.Module):
    """
    Freezes all BEiT-related weights except the last decoder layer.
    """
    # print("\nğŸ” Before freezing:")

    # Freeze encoder, backbone, and positional embedding
    for param in model.encoder.parameters():
        param.requires_grad = False

    for param in model.backbone.parameters():
        param.requires_grad = False

    for param in model.pos_embed.parameters():
        param.requires_grad = False

    # Freeze decoder layers 0, 1, 2 and keep the last layer (3) trainable
    decoder_layers = model.decoder.decoder.layers
    for i, layer in enumerate(decoder_layers):
        for param in layer.parameters():
            param.requires_grad = (i == 3)  # Only last decoder layer trainable



def turn_on_beit_grad(model: nn.Module):
    for param in model.parameters():
        param.requires_grad = True


def create_mix_tokens(vocab_html, vocab_bbox):
    # merged_vocabì„ êµ¬ì„±í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ vocab_html ë”•ì…”ë„ˆë¦¬ì™€ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    new_vocab_html = {}
    old_to_new_mapping_html = {}

    # ì˜¤ë¥¸ìª½ í† í°("]</td>")ì˜ í‚¤ë¥¼ ì¼ê´€ë˜ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ (ì¡°ê±´ì— ë§ê²Œ ì •í™•íˆ í‘œê¸°)
    right_token = "]</td>"

    # vocab_htmlì˜ í•­ëª©ë“¤ì„ ì¸ë±ìŠ¤ ìˆœìœ¼ë¡œ ìˆœíšŒí•©ë‹ˆë‹¤.
    # (ì›ë˜ vocab_htmlì€ í† í°â†’ì¸ë±ìŠ¤ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.)
    for token, idx in sorted(vocab_html.items(), key=lambda x: x[1]):
        if token == "<td>[]</td>":
            # ì¡°ê±´ 2: ì›ë˜ì˜ ì¸ë±ìŠ¤(idx)ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ "<td>["ì— í• ë‹¹
            new_vocab_html["<td>["] = idx
            # ì¡°ê±´ 4: ìƒˆ í† í° "]</td>"ë¥¼ vocab_htmlì˜ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ + 1ë¡œ ì¶”ê°€ (ì•„ì§ ì¶”ê°€ë˜ì§€ ì•Šì•˜ë‹¤ë©´)
            if right_token not in new_vocab_html:
                new_index = max(vocab_html.values()) + 1
                new_vocab_html[right_token] = new_index
            # ë§¤í•‘: ì›ë˜ "<td>[]</td>"ì˜ ì¸ë±ìŠ¤ idxê°€ ë¶„ë¦¬ë˜ì–´, leftëŠ” idx, rightëŠ” ìƒˆë¡œ ì¶”ê°€ëœ ì¸ë±ìŠ¤ë¡œ ê¸°ë¡
            old_to_new_mapping_html[idx] = {"left": idx, "right": new_vocab_html[right_token]}
        elif token == ">[]</td>":
            # ì¡°ê±´ 3: ì›ë˜ì˜ ì¸ë±ìŠ¤(idx)ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ">["ì— í• ë‹¹
            new_vocab_html[">["] = idx
            # ì¡°ê±´ 4: ìƒˆ í† í° "]</td>"ê°€ ì—†ìœ¼ë©´ ì¶”ê°€ (ì´ë¯¸ ì¶”ê°€ë˜ì–´ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            if right_token not in new_vocab_html:
                new_index = max(vocab_html.values()) + 1
                new_vocab_html[right_token] = new_index
            old_to_new_mapping_html[idx] = {"left": idx, "right": new_vocab_html[right_token]}
        else:
            # ê·¸ ì™¸ í† í°ì€ ê·¸ëŒ€ë¡œ ë³µì‚¬
            new_vocab_html[token] = idx
            old_to_new_mapping_html[idx] = idx  # ë³€í™˜ì´ ì—†ìœ¼ë©´ ì›ë˜ ì¸ë±ìŠ¤ë¡œ ê¸°ë¡

    # ---------------

    # vocab_bbox ì²˜ë¦¬ (ì¡°ê±´ 5)
    # vocab_bboxì˜ ëª¨ë“  í† í° ì¸ë±ìŠ¤ì— new_vocab_htmlì˜ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ + 1 ë§Œí¼ì˜ ì˜¤í”„ì…‹ì„ ë”í•©ë‹ˆë‹¤.
    offset = max(new_vocab_html.values()) + 1
    new_vocab_bbox = { token: (idx + offset) for token, idx in vocab_bbox.items() }

    # ë‘ vocabì„ ë³‘í•©í•©ë‹ˆë‹¤.
    merged_vocab = {**new_vocab_html, **new_vocab_bbox}

    # ì¶”ê°€ ê°œë°œì‚¬í•­: ê¸°ì¡´ bbox vocabì˜ ì¸ë±ìŠ¤ì™€ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    old_to_new_mapping_bbox = { idx: (idx + offset) for token, idx in vocab_bbox.items() }

    # ---------------

    # íƒ€ê²Ÿ ì¸ë±ìŠ¤ ì„¤ì •
    # HTML íƒ€ê²Ÿ: ìƒˆë¡­ê²Œ ìƒì„±ëœ ">["ì™€ "<td>["ì˜ ì¸ë±ìŠ¤
    html_target_indices = [
        new_vocab_html.get(">["),      # ">["ê°€ ì›ë˜ ">[]</td>"ì˜ ì¸ë±ìŠ¤ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì§
        new_vocab_html.get("<td>[")      # "<td>["ê°€ ì›ë˜ "<td>[]</td>"ì˜ ì¸ë±ìŠ¤ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì§
    ]

    # BBOX íƒ€ê²Ÿ: mergedëœ bbox vocab(new_vocab_bbox)ì—ì„œ "bbox"ë¼ëŠ” ë¬¸ìì—´ì´ í¬í•¨ëœ í† í°ë“¤ì˜ ì¸ë±ìŠ¤ ëª¨ë‘
    bbox_target_indices = [
        new_vocab_bbox[token] for token in new_vocab_bbox if "bbox" in token.lower()
    ]

    # ---------------

    # ê°ì²´ ë³€ìˆ˜ì— ì €ì¥
    merged_vocab = merged_vocab
    html_target_indices = html_target_indices
    bbox_target_indices = bbox_target_indices
    old_to_new_mapping_html = old_to_new_mapping_html
    old_to_new_mapping_bbox = old_to_new_mapping_bbox

    return old_to_new_mapping_html, old_to_new_mapping_bbox, html_target_indices, bbox_target_indices





class Batch:
    """Wrap up a batch of training samples with different training targets.
    The input is not torch tensor
    Shape of the image (src): B, S, E
    Shape of the text (tgt): B, N, S, E (M includes 1 table detection, 1 structure, 1 cell, and multiple bbox)
    Reshape text to (B * N, S, E) and inflate the image to match the shape of the text

    Args:
    ----
        device: gpu id
    """

    def __init__(
        self,
        device: torch.device,
        target: str,
        vocab: Vocab,
        obj: List,
    ) -> None:
        self.device = device
        self.image = obj[0].to(device)
        self.name = obj[1]["filename"]
        self.target = target
        self.vocab = vocab
        self.image_size = self.image.shape[-1]

        if "table" in target:
            raise NotImplementedError

        if "html" in target:

            self.valid_html_token = [vocab.token_to_id(i) for i in VALID_HTML_TOKEN]
            (
                self.html_src,
                self.html_tgt,
                self.html_casual_mask,
                self.html_padding_mask,
            ) = self._prepare_transformer_input(obj[1]["html"])

        if "cell" in target:
            self.invalid_cell_token = [vocab.token_to_id(i) for i in INVALID_CELL_TOKEN]
            (
                self.cell_src,
                self.cell_tgt,
                self.cell_casual_mask,
                self.cell_padding_mask,
            ) = self._prepare_transformer_input(obj[1]["cell"])

        if "bbox" in target:
            (
                self.bbox_src,
                self.bbox_tgt,
                self.bbox_casual_mask,
                self.bbox_padding_mask,
            ) = self._prepare_transformer_input(obj[1]["bbox"])

        
    def _prepare_transformer_input(
        self, seq: List[tk.Encoding]
    ) -> Tuple[Tensor, Tensor, Tensor, Tensor]:
        tmp = [i.ids for i in seq]
        tmp = torch.tensor(tmp, dtype=torch.int32)
        src = tmp[:, :-1].to(self.device)
        tgt = tmp[:, 1:].type(torch.LongTensor).to(self.device)
        casual_mask = subsequent_mask(src.shape[-1]).to(self.device)
        tmp = [i.attention_mask[:-1] for i in seq]  # padding mask
        tmp = torch.tensor(tmp, dtype=torch.bool)
        padding_mask = (~tmp).to(self.device)

        return src, tgt, casual_mask, padding_mask

    def _inference_one_task(
        self, model, memory, src, casual_mask, padding_mask, use_ddp
    ):
        if use_ddp:
            out = model.module.decode(memory, src, casual_mask, padding_mask)
            out = model.module.generator(out)
        else:
            out = model.decode(memory, src, casual_mask, padding_mask)
            out = model.generator(out)

        return out

    def inference(
        self,
        model: nn.Module,
        criterion: nn.Module,
        criterion_bbox: nn.Module = None,
        loss_weights: dict = None,
        use_ddp: bool = True,
    ) -> Tuple[Dict, Dict]:
        pred = dict()
        loss = dict(table=0, html=0, cell=0, bbox=0)

        if use_ddp:
            memory = model.module.encode(self.image)
        else:
            memory = model.encode(self.image)

        # inference + suppress invalid logits + compute loss
        if "html" in self.target:
            out_html = self._inference_one_task(
                model,
                memory,
                self.html_src,
                self.html_casual_mask,
                self.html_padding_mask,
                use_ddp,
            )

            pred["html"] = pred_token_within_range(
                out_html, white_list=self.valid_html_token
            ).permute(0, 2, 1)
            loss["html"] = criterion(pred["html"], self.html_tgt)
            # print(f'pred html : {pred["html"]}')

        if "cell" in self.target:
            out_cell = self._inference_one_task(
                model,
                memory,
                self.cell_src,
                self.cell_casual_mask,
                self.cell_padding_mask,
                use_ddp,
            )

            pred["cell"] = pred_token_within_range(
                out_cell, black_list=self.invalid_cell_token
            ).permute(0, 2, 1)
            loss["cell"] = criterion(pred["cell"], self.cell_tgt)

        if "bbox" in self.target:
            assert criterion_bbox is not None

            out_bbox = self._inference_one_task(
                model,
                memory,
                self.bbox_src,
                self.bbox_casual_mask,
                self.bbox_padding_mask,
                use_ddp,
            )
            pred["bbox"] = out_bbox.permute(0, 2, 1)
            loss["bbox"] = criterion_bbox(pred["bbox"], self.bbox_tgt)

        total = 0.0
        for k, v in loss_weights.items():
            total += loss[k] * v
        loss["total"] = total

        return loss, pred
